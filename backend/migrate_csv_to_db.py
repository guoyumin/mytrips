#!/usr/bin/env python3
"""
CSVæ•°æ®è¿ç§»åˆ°SQLiteæ•°æ®åº“
"""

import os
import sys
import csv
from datetime import datetime
from typing import Dict, List

# æ·»åŠ åç«¯ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(__file__))

from database.config import SessionLocal, engine
from database.models import Email, Base
from lib.config_manager import config_manager
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def parse_email_date(date_str: str) -> datetime:
    """è§£æé‚®ä»¶æ—¥æœŸå­—ç¬¦ä¸²ä¸ºdatetimeå¯¹è±¡"""
    if not date_str:
        return None
    
    try:
        # å°è¯•è§£æ Gmail æ—¥æœŸæ ¼å¼
        from email.utils import parsedate_to_datetime
        dt = parsedate_to_datetime(date_str)
        # ç§»é™¤æ—¶åŒºä¿¡æ¯ä»¥é¿å…SQLiteå…¼å®¹æ€§é—®é¢˜
        return dt.replace(tzinfo=None)
    except Exception as e:
        logger.warning(f"Failed to parse date '{date_str}': {e}")
        return None

def load_csv_data(csv_file: str) -> List[Dict]:
    """ä»CSVæ–‡ä»¶åŠ è½½æ•°æ®"""
    emails = []
    
    if not os.path.exists(csv_file):
        logger.warning(f"CSV file not found: {csv_file}")
        return emails
    
    logger.info(f"Loading data from CSV: {csv_file}")
    
    with open(csv_file, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        
        for row_num, row in enumerate(reader, 1):
            try:
                email_data = {
                    'email_id': row.get('email_id', '').strip(),
                    'subject': row.get('subject', '').strip() or None,
                    'sender': row.get('from', '').strip() or None,  # CSVä¸­æ˜¯'from'ï¼ŒDBä¸­æ˜¯'sender'
                    'date': row.get('date', '').strip() or None,
                    'timestamp': parse_email_date(row.get('date', '')),
                    'is_classified': row.get('is_classified', 'false').lower() == 'true',
                    'classification': row.get('classification', '').strip() or None
                }
                
                # éªŒè¯å¿…éœ€å­—æ®µ
                if not email_data['email_id']:
                    logger.warning(f"Row {row_num}: Missing email_id, skipping")
                    continue
                
                emails.append(email_data)
                
            except Exception as e:
                logger.error(f"Row {row_num}: Error processing row: {e}")
                continue
    
    logger.info(f"Loaded {len(emails)} emails from CSV")
    return emails

def migrate_to_database(emails: List[Dict]) -> int:
    """å°†é‚®ä»¶æ•°æ®è¿ç§»åˆ°æ•°æ®åº“"""
    if not emails:
        logger.info("No emails to migrate")
        return 0
    
    db = SessionLocal()
    try:
        # è·å–ç°æœ‰é‚®ä»¶IDä»¥é¿å…é‡å¤
        existing_ids = set(
            db.query(Email.email_id).all()
        )
        existing_ids = {email_id[0] for email_id in existing_ids}
        
        logger.info(f"Found {len(existing_ids)} existing emails in database")
        
        # è¿‡æ»¤å‡ºæ–°é‚®ä»¶
        new_emails = []
        for email_data in emails:
            if email_data['email_id'] not in existing_ids:
                new_emails.append(Email(**email_data))
        
        logger.info(f"Preparing to insert {len(new_emails)} new emails")
        
        if new_emails:
            # æ‰¹é‡æ’å…¥
            db.add_all(new_emails)
            db.commit()
            logger.info(f"âœ… Successfully migrated {len(new_emails)} emails to database")
        else:
            logger.info("No new emails to migrate (all already exist)")
        
        return len(new_emails)
        
    except Exception as e:
        db.rollback()
        logger.error(f"âŒ Migration failed: {e}")
        raise
    finally:
        db.close()

def get_migration_stats(db_session) -> Dict:
    """è·å–è¿ç§»ç»Ÿè®¡ä¿¡æ¯"""
    stats = {}
    
    try:
        # æ€»é‚®ä»¶æ•°
        stats['total_emails'] = db_session.query(Email).count()
        
        # å·²åˆ†ç±»é‚®ä»¶æ•°
        stats['classified_emails'] = db_session.query(Email).filter(Email.is_classified == True).count()
        
        # åˆ†ç±»åˆ†å¸ƒ
        classifications = db_session.query(
            Email.classification, 
            db_session.query(Email).filter(Email.classification == Email.classification).count()
        ).filter(Email.classification.isnot(None)).distinct().all()
        
        stats['classifications'] = {cls: count for cls, count in classifications}
        
        # æ—¥æœŸèŒƒå›´
        date_range = db_session.query(
            db_session.query(Email.timestamp).filter(Email.timestamp.isnot(None)).order_by(Email.timestamp.asc()).first(),
            db_session.query(Email.timestamp).filter(Email.timestamp.isnot(None)).order_by(Email.timestamp.desc()).first()
        ).first()
        
        if date_range and date_range[0] and date_range[1]:
            stats['date_range'] = {
                'oldest': date_range[0][0].strftime('%Y-%m-%d'),
                'newest': date_range[1][0].strftime('%Y-%m-%d')
            }
        
    except Exception as e:
        logger.error(f"Failed to get stats: {e}")
    
    return stats

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("MyTrips: CSVæ•°æ®è¿ç§»åˆ°SQLiteæ•°æ®åº“")
    print("=" * 60)
    
    try:
        # è·å–CSVæ–‡ä»¶è·¯å¾„
        csv_file = config_manager.get_cache_file_path()
        logger.info(f"CSV file: {csv_file}")
        
        # æ£€æŸ¥CSVæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(csv_file):
            logger.error(f"CSV file not found: {csv_file}")
            return False
        
        # åŠ è½½CSVæ•°æ®
        emails = load_csv_data(csv_file)
        
        if not emails:
            logger.warning("No emails found in CSV file")
            return True
        
        # è¿ç§»åˆ°æ•°æ®åº“
        migrated_count = migrate_to_database(emails)
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        db = SessionLocal()
        try:
            stats = get_migration_stats(db)
            
            print(f"\nğŸ“Š è¿ç§»å®Œæˆç»Ÿè®¡:")
            print(f"  â€¢ æ–°å¢é‚®ä»¶: {migrated_count}")
            print(f"  â€¢ æ•°æ®åº“æ€»é‚®ä»¶æ•°: {stats.get('total_emails', 0)}")
            print(f"  â€¢ å·²åˆ†ç±»é‚®ä»¶æ•°: {stats.get('classified_emails', 0)}")
            
            if stats.get('date_range'):
                print(f"  â€¢ æ—¥æœŸèŒƒå›´: {stats['date_range']['oldest']} åˆ° {stats['date_range']['newest']}")
            
            if stats.get('classifications'):
                print(f"  â€¢ åˆ†ç±»åˆ†å¸ƒ:")
                for classification, count in stats['classifications'].items():
                    print(f"    - {classification}: {count}")
        
        finally:
            db.close()
        
        print(f"\nğŸ‰ æ•°æ®è¿ç§»æˆåŠŸå®Œæˆï¼")
        return True
        
    except Exception as e:
        logger.error(f"Migration failed: {e}")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)